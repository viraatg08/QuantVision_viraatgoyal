{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN6mivfu7v53PUFqZ0Fp1RR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"rHtdTPt1Glrp","executionInfo":{"status":"ok","timestamp":1766424491705,"user_tz":-330,"elapsed":2012,"user":{"displayName":"VIRAAT GOYAL","userId":"17639306585596031002"}},"outputId":"5953b39d-d0b2-491d-b307-dfbad36ad26b"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wu8tOc9aYlL7","executionInfo":{"status":"ok","timestamp":1766430264625,"user_tz":-330,"elapsed":752,"user":{"displayName":"VIRAAT GOYAL","userId":"17639306585596031002"}},"outputId":"86da635a-5645-485a-f776-5eddd7ecce09"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======= Classification Report for logmodel =======\n","               precision    recall  f1-score   support\n","\n","           0       0.67      0.50      0.57         4\n","           1       0.96      0.98      0.97        56\n","\n","    accuracy                           0.95        60\n","   macro avg       0.82      0.74      0.77        60\n","weighted avg       0.95      0.95      0.95        60\n","\n","\n","Confusion mstrix :\n"," [[ 2  2]\n"," [ 1 55]]\n","\n","======= Classification Report for nn_model =======\n","               precision    recall  f1-score   support\n","\n","           0       0.75      0.75      0.75         4\n","           1       0.98      0.98      0.98        56\n","\n","    accuracy                           0.97        60\n","   macro avg       0.87      0.87      0.87        60\n","weighted avg       0.97      0.97      0.97        60\n","\n","\n","Confusion mstrix :\n"," [[ 3  1]\n"," [ 1 55]]\n"]}],"source":["import pandas as pd\n","\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.pipeline import Pipeline\n","\n","df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/quantvision_financial_dataset_200.csv')\n","num_features = ['lookback_days','high_volatility','trend_continuation', 'technical_score', 'edge_density',\n","                'slope_strength', 'candlestick_variance', 'pattern_symmetry']\n","cat_features = ['asset_type', 'market_regime']\n","x = df.drop('future_trend', axis=1)\n","y = df['future_trend']\n","\n","preprocessing = ColumnTransformer(\n","    transformers=[\n","        ('num', StandardScaler(), num_features),\n","        ('cat', OneHotEncoder(drop = \"first\"), cat_features)\n","    ]\n",")\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42,stratify = y)\n","\n","logmodel = log_model=Pipeline(steps=[\n","    (\"preprocessor\", preprocessing),\n","     (\"classifier\", LogisticRegression(\n","         random_state=7,\n","         max_iter=1000\n","         ))\n","     ])\n","\n","logmodel.fit(x_train, y_train)\n","y_pred_logmodel = logmodel.predict(x_test)\n","print(\"\\n======= Classification Report for logmodel =======\\n\", classification_report(y_test, y_pred_logmodel))\n","print( \"\\nConfusion mstrix :\\n\",confusion_matrix(y_test, y_pred_logmodel))\n","\n","nn_model=Pipeline(steps=[\n","    (\"preprocessor\", preprocessing),\n","    (\"classifier\", MLPClassifier(\n","        hidden_layer_sizes=(64, 32),\n","        activation=\"relu\",\n","        solver=\"adam\",\n","        max_iter=1000,\n","        random_state=7\n","    ))\n","])\n","nn_model.fit(x_train, y_train)\n","y_pred_nn_model = nn_model.predict(x_test)\n","print(\"\\n======= Classification Report for nn_model =======\\n\", classification_report(y_test, y_pred_nn_model))\n","print( \"\\nConfusion mstrix :\\n\",confusion_matrix(y_test, y_pred_nn_model))"]},{"cell_type":"code","source":["# Why Logistic Regression performs reasonably good or bad\n","#due to it's linear nature the model might not be able to fit certain data points on a straight line.\n","\n","# Why Neural Network performs better or worse\n","#neural networks work in a non linear manner.It identifies trends on various factor and works like a decision tree.\n","\n","#The effect of volatility on predictions\n","#high volatility means high engy in the market which can either cause prices to soar high or a caos in the price trends,\n","# logistic regression struggles with this as there will many outliers in its patter which will result in bad prediction.\n","\n","# The role of trend continuation\n","#helps in increasing accuracy for both the models as the classification of datapoints are predictible\n","\n","# Situations where the model fails and why\n","#models fails in situations of high volatility with causes and unstable market price,this makes it difficult for the models to make clear trends.\n","# the logistic regrssion model might not be able to fit a straight line through the messy datapoints\n","# whereas NN might overfit(memorize) certain patters in the data (like high volatility +high technical score)\n","# which will not happen in the future leading to poor predictions."],"metadata":{"id":"BNTzZvYNdncB","executionInfo":{"status":"ok","timestamp":1766430522147,"user_tz":-330,"elapsed":17,"user":{"displayName":"VIRAAT GOYAL","userId":"17639306585596031002"}}},"execution_count":58,"outputs":[]}]}